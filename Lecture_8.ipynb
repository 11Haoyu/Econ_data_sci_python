{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series Analysis\n",
    "\n",
    "Zhentao Shi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Practical topics\n",
    "* Useful in business contexts\n",
    "* Modeling choices and challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Time Series Regression\n",
    "* Univariate Time Series Models\n",
    "* Nonstationary Time Series\n",
    "* Multivariate Time Series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Traditionally, small models\n",
    "* High dimensional time series modeling is work in progress\n",
    "* Predictive regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Common Operations\n",
    "\n",
    "* Lag Operator\n",
    "\n",
    "$$L x_t = x_{t-1}$$\n",
    "$$L^{\\tau} x_t = x_{t-\\tau}$$ \n",
    "\n",
    "* Difference operator\n",
    "$$\\Delta x_t = x_t - x_{t-1} = (1-L) x_t$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lagged Effect\n",
    "\n",
    "* Interpretation as a generative model\n",
    "\n",
    "$$y_t = \\alpha + \\sum_{i=0}^{\\infty} \\beta_i  x_{t-i} + e_t$$\n",
    "\n",
    "* Impact multiplier: $\\beta_0$\n",
    "* Cumulated effect (of $\\tau$ periods): $\\sum_{i=0}^{\\tau} \\beta_i $\n",
    "* Equilibrium multiplier: $\\sum_{i=0}^{\\infty} \\beta_i $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stationary Time Series\n",
    "\n",
    "For a univariate time series $(y_t)_{t= - \\infty} ^ {\\infty}$,\n",
    "* **Strictly stationary**: joint distribution of any finite coordinate only depends on their relative position.\n",
    "* **Weakly stationary**: the first two moments of any pair $y_t$ and $y_s$ only depends on their relative position.\n",
    "    * $E[y_t] = \\mu$ for all $t$\n",
    "    * $\\mathrm{var}[y_t] = \\sigma^2$ for all $t$\n",
    "    * $\\mathrm{cov}[y_t, y_{t+\\tau} ] $ only depends on $\\tau$ independent of $t$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "This notion can be extended to multiple-variate time series, for example $(y_t, x_t, e_t)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributed Lags\n",
    "\n",
    "* Lagged $x$ on the right-hand side\n",
    "\n",
    "$$\n",
    "y_t = \\alpha + \\sum_{i=0}^{\\infty} \\beta_i  x_{t-i} + e_t = \\alpha + B(L) x_t + e_t \n",
    "$$\n",
    "\n",
    "where $$B(L) = \\sum_{i=0}^{\\infty} \\beta_i L^i$$ is a polynomial of the lag operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Autoregressive model\n",
    "\n",
    "* Lagged $y$ on the right-hand side\n",
    "\n",
    "$$\n",
    "y_t = \\alpha + \\sum_{i=1}^p \\gamma_p y_{t-p} + e_t \n",
    "$$ \n",
    "\n",
    "can be written as \n",
    "\n",
    "$$\n",
    "C(L) y_t = \\alpha + e_t\n",
    "$$ \n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "C(L) = 1 -\\gamma_1 L - \\cdots - \\gamma_p L^p\n",
    "$$ \n",
    "\n",
    "is a polynomial of the lag operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Invertibility\n",
    "\n",
    "If the roots of the polynomial equation $C(z) = 0$ **all** lies **outside** of the unit circle, we say the autoregressive model is invertible.\n",
    "\n",
    "\n",
    "\n",
    "If $e_t$ is stationary with finite variance and $\\alpha=0$ (homogenous difference equation):\n",
    "* If the module of the smallest root is bigger than 1, $y_t$ is a stationary time series\n",
    "* If the module of the smallest root is equal to 1, $y_t$ is a **unit root** process\n",
    "* If the module of the smallest root is smaller than 1, $y_t$ is an **explosive** process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Numerical Example\n",
    "\n",
    "* $C(L) = 1 - 0.5L$ is invertible.\n",
    "* $C(L) = 1 - L$ is non-invertible.\n",
    "* $C(L) = 1 - 1.1L$ is non-invertible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def AR(b, T):\n",
    "    y = np.zeros(T)\n",
    "    for t in range(T):\n",
    "        if t > 0:\n",
    "            y[t] = b * y[t - 1] + np.random.normal()\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = 100\n",
    "y = AR(0.5, T)\n",
    "\n",
    "plt.plot(range(1, T+1), y)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"AR(0.5)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "T = 100\n",
    "y = AR(1.0, T)\n",
    "\n",
    "plt.plot(range(1, T+1), y)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"AR(1.0)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "T = 100\n",
    "y = AR(1.05, T)\n",
    "\n",
    "plt.plot(range(1, T+1), y)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"AR(1.05)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autoregressive Distributed Lag Models\n",
    "\n",
    "\n",
    "* ARDL(p,r) model:\n",
    "\n",
    "$$\n",
    "C(L) y_t = \\mu + B(L) x_t + e_t \n",
    "$$ \n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "C(L) = 1 -\\gamma_1 L - \\cdots - \\gamma_p L^p\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "B(L) =  \\beta_0 + \\beta_1 L + \\cdots + \\beta_r L^r.\n",
    "$$\n",
    "\n",
    "* **Granger causality**: \n",
    "\n",
    "$$\n",
    "\\beta_0 = \\beta_1 = \\cdots = \\beta_r = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example\n",
    "\n",
    "* In simple regression form\n",
    "\n",
    "$$\n",
    "y_t = \\beta_1 + \\beta_2 x_t + \\beta_3 x_{t-1} + \\gamma y_{t-1} + e_t\n",
    "$$\n",
    "\n",
    "* Temporal lags of effect. eg: policy lag\n",
    "* Expectation formed from the past. eg: forecast\n",
    "* Explicitly depends on history. eg: wealth accumulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "POILBREUSDQ = pdr.get_data_fred('POILBREUSDQ') # Brent Oil price\n",
    "IPB50001SQ = pdr.get_data_fred('IPB50001SQ') # industrial Index (quarterly data)\n",
    "\n",
    "d0 = pd.merge(POILBREUSDQ, IPB50001SQ, left_index=True, right_index=True).dropna()\n",
    "d0 = d0.assign(x = pd.Series(d0['POILBREUSDQ'], index=d0.index))\n",
    "d0 = d0.assign(y = pd.Series(d0['IPB50001SQ'], index=d0.index))\n",
    "\n",
    "del POILBREUSDQ, IPB50001SQ\n",
    "\n",
    "print(d0.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(d0.index, d0)\n",
    "plt.title(\"\")\n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ARDL(1,1) regression example\n",
    "\n",
    "* `dynlm` only works with objects `ts()`. The transformation is essential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Generate random data for the time series\n",
    "np.random.seed(42)\n",
    "y = np.random.randn(100).cumsum()\n",
    "x = np.random.randn(100).cumsum()\n",
    "\n",
    "# Create a DataFrame\n",
    "d0 = pd.DataFrame({'y': y, 'x': x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as smt\n",
    "\n",
    "# Define the number of lags\n",
    "lags = 1\n",
    "\n",
    "# Fit the VAR model\n",
    "model = smt.VAR(d0)\n",
    "results = model.fit(lags)\n",
    "\n",
    "# Print the summary of the model\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Differenced dependent variable (`d( )`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Calculate the first difference of 'y'\n",
    "d0['dy'] = d0['y'].diff()\n",
    "\n",
    "# Prepare the endogenous variable\n",
    "endog = d0['dy'].iloc[1:].reset_index(drop=True)\n",
    "\n",
    "# Prepare the exogenous variables\n",
    "exog = sm.add_constant(d0[['y', 'x']].iloc[:-1]).astype(float).reset_index(drop=True)\n",
    "\n",
    "# Create and fit the OLS model\n",
    "model = sm.OLS(endog, exog)\n",
    "results = model.fit()\n",
    "\n",
    "# Print the summary\n",
    "print(results.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Spurious Regression\n",
    "\n",
    "\n",
    "* The two time series $\\{y_t\\}$ and $\\{x_t\\}$ are generated independently, so that $E[y_t|x_t] = 0$. \n",
    "* However, we observe a high $R^2$ and large t-value if we regression $y_t$ against $x_t$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "T = 50\n",
    "a = 1\n",
    "\n",
    "y = AR(a, T)\n",
    "x = AR(a, T)\n",
    "\n",
    "plt.plot(y, label=\"y\")\n",
    "plt.plot(x, label=\"x\")\n",
    "plt.ylabel(\"\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# import statsmodels.api as sm\n",
    "\n",
    "reg = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "\n",
    "print(reg.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discovery\n",
    "\n",
    "* Granger and Newbold (1974): If we naively use 1.96 as the critical value for the $t$-ratio, how often we would reject the null hypothesis that $\\beta = 0$?  \n",
    "\n",
    "* The nominal asymptotic test size is $5\\%$ according to the standard asymptotic theory\n",
    "* The empirical size is about 0.80 in this simulation\n",
    "* The drastic deviation suggests that the standard asymptotic theory fails in the nonstationary environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def spurious(i, a, T):\n",
    "    y = AR(a, T)\n",
    "    x = AR(a, T)\n",
    "\n",
    "    reg = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "    p_val = reg.pvalues[1]\n",
    "    # save the p-value of the estimate of x's coefficient\n",
    "    return p_val\n",
    "\n",
    "out = []\n",
    "for i in tqdm(range(1000)):\n",
    "    p_val = spurious(i, 1.0, 100)\n",
    "    out.append(p_val)\n",
    "\n",
    "print(np.mean(np.array(out) < 0.05))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Autoregression and Moving Average\n",
    "\n",
    "* Box-Jenkins (1976): ARMA\n",
    "* No economic theory. For fitting and prediction only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Simple Models\n",
    "\n",
    "* White noise: $(e_t)_{t=-\\infty}^{\\infty}$:\n",
    "    * $E[e_t] = 0$, $E[e_t^2] = \\sigma_e^2$, and $E[e_t, e_s] = 0$ for all $t\\neq s$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ARMA\n",
    "\n",
    "\n",
    "* AR(p) $$ y_t = \\mu + \\gamma_1 y_{t-1} + \\cdots \\gamma_p y_{t-p} + e_t $$\n",
    "* MA(q) $$ y_t = \\mu + e_t - \\theta_1 e_{t-1} - \\theta_q e_{t-q} + e_t $$\n",
    "* ARMA(p,q) $$(1-\\Gamma(L) ) y_t = \\mu + \\Theta (L) e_t$$\n",
    "\n",
    "Stationarity: in AR form whether all roots lies out of the unit cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Autocorrelation Patterns\n",
    "\n",
    "\n",
    "* MA(q): finite dependence\n",
    "* AR(1): geometric decline\n",
    "    * $E[ y_t ] = \\mu / (1-\\gamma_1)$\n",
    "    * $\\mathrm{var}[y_t] = \\sigma_e^2 / (1-\\gamma_1^2 )$\n",
    "    * $E[ y_t | y_{t-1} ] = \\mu + \\gamma_1 y_{t-1}$\n",
    "    * $\\mathrm{var}[y_t | y_{t-1} ] = \\sigma_e^2 $\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modeling\n",
    "\n",
    "* ARIMA(p, r, q) $$(1-\\Gamma(L) ) \\Delta^r y_t = \\mu + \\Theta (L) e_t$$\n",
    "* Transform into stationary time series by taking logarithm and/or difference.\n",
    "* Fit ARMA(p,q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "reg1 = sm.tsa.ARIMA(d0['x'], order=(2,0,3)).fit()\n",
    "print(reg1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "reg2 = sm.tsa.ARIMA(d0['x'], order=(2,1,3)).fit()\n",
    "print(reg2.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Seasonality\n",
    "\n",
    "* Generated due to sampling frequency\n",
    "  * Eg: traffic data; electronic consumption\n",
    "* Add dummies to control seasonality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimation\n",
    "\n",
    "* MLE for MA(q)\n",
    "* MLE for ARMA(p,q)\n",
    "* OLS for AR(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Model Choice\n",
    "\n",
    "Information criteria. \n",
    "\n",
    "Let $k$ be the total number of slope coefficient in the model.\n",
    "\n",
    "* Akaike information criterion: $\\log( \\hat{\\sigma}^2 ) + 2\\times (k / T )$. \n",
    "    * Tend to overfit, but better for prediction\n",
    "* Bayesian information criterion: $\\log( \\hat{\\sigma}^2 ) + \\log(T) \\times (k / T )$\n",
    "    * Model selection consistent\n",
    "    \n",
    "Information criteria are not restricted to time series regressions. They are general statistical measures for model/variable selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(reg1.aic)\n",
    "print(reg2.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Unit Root\n",
    "\n",
    "* AR(1) with AR coefficient equals 1. $$y_t = \\mu + y_{t-1} + e_t $$\n",
    "* Nonstationary\n",
    "* Brownian motion: normal innovation\n",
    "* Random walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implication\n",
    "* conditional and unconditional mean\n",
    "* conditional and unconditional variance\n",
    "* $h$-period ahead forecast"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The OLS estimator \n",
    "\n",
    "$$\n",
    "T(\\hat{\\gamma}_1 - 1) \\stackrel{d}{\\to} \\text{ a stable distribution}.\n",
    "$$\n",
    "\n",
    "but the asymptotic distribution is not normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas_datareader.data as web\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import yfinance as yf\n",
    "\n",
    "# Download S&P 500 (^GSPC) data\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2023-01-01'\n",
    "ticker = '^GSPC'\n",
    "sp500_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "y=sp500_data\n",
    "\n",
    "plt.plot(y)\n",
    "plt.show()\n",
    "\n",
    "print(y.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Null hypothesis: unit root.\n",
    "$$ \\Delta y_t = \\mu + (\\gamma_1 - 1 ) y_{t-1} + e_t = \\mu+ \\theta y_{t-1} + e_t$$\n",
    "where $ \\theta = \\gamma_1 - 1 $. Under the null, $\\theta = 0$.\n",
    "\n",
    "* The $t$-statistic is the test statistic for the Dicky-Fuller test.\n",
    "* Under the null, the $t$-statistic asymptotically follows a pivotal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* In this numerical example, the test does not reject the null.\n",
    "\n",
    "Notice: the test is one-sided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "result = adfuller(y, regression='c', autolag='AIC')\n",
    "print('ADF Statistic: ', result[0])\n",
    "print('p-value: ', result[1])\n",
    "for key, value in result[4].items():\n",
    "    print('Critical Values:')\n",
    "    print(key, value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "y = sm.tsa.ArmaProcess(ar=[1, -0.8], ma=[1]).generate_sample(nsample=100)\n",
    "\n",
    "plt.plot(y)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def generate_ar_series(ar, n):\n",
    "    y = np.zeros(n)\n",
    "    e = np.random.randn(n)\n",
    "\n",
    "    for i in range(1, n):\n",
    "        y[i] = ar * y[i - 1] + e[i]\n",
    "\n",
    "    return y\n",
    "\n",
    "def DF_sim(ar):\n",
    "    Rep = 500\n",
    "    n = 100\n",
    "\n",
    "    B_hat = np.zeros(Rep)\n",
    "\n",
    "    for r in range(Rep):\n",
    "        y = generate_ar_series(ar, n)\n",
    "        reg_dyn = OLS(y[1:], np.vstack([np.ones(n-1), y[:-1]]).T).fit()\n",
    "        B_hat[r] = reg_dyn.params[1]\n",
    "\n",
    "    return B_hat\n",
    "\n",
    "def plot_density(B, color, label):\n",
    "    density = gaussian_kde(B)\n",
    "    x = np.linspace(min(B), max(B), 100)\n",
    "    plt.plot(x, density(x), color=color, label=label)\n",
    "\n",
    "B = DF_sim(1)\n",
    "plot_density(B, color=\"red\", label=\"ar=1\")\n",
    "\n",
    "B = DF_sim(0.5)\n",
    "plot_density(B, color=\"blue\", label=\"ar=0.5\")\n",
    "\n",
    "B = DF_sim(0.9)\n",
    "plot_density(B, color=\"purple\", label=\"ar=0.9\")\n",
    "\n",
    "plt.xlim(0, 1.1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Specification of DF test\n",
    "\n",
    "* The error term must be a white noise for the DF distribution\n",
    "* DF test's critical values vary with the specfication of drift and/or trend\n",
    "* Augmented Dicky-Fuller test: add more differenced lag terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other tests\n",
    "* Phillips-Perron test\n",
    "* KPSS test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from arch.unitroot import PhillipsPerron\n",
    "\n",
    "pp_test = PhillipsPerron(y)\n",
    "print(pp_test.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "result = kpss(y, regression='c', lags='auto')\n",
    "print('KPSS Statistic: ', result[0])\n",
    "print('p-value: ', result[1])\n",
    "for key, value in result[3].items():\n",
    "    print('Critical Values:')\n",
    "    print(key, value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Time Series Filtering\n",
    "\n",
    "**Hodrick-Prescott filter**: Decompose a time series into *trend* and *cycle*\n",
    "\n",
    "$$\\hat{f}_{t}=\\arg \\min_{f_{t}}\\left\\{ \\sum_{t=1}^{n}\\left( y_{t}-f_{t}\\right)^{2}+\\lambda \\sum_{t=3}^{n}\\left( \\Delta ^{2}f_{t}\\right) ^{2}\\right\\}.$$\n",
    "    \n",
    "Hodrick Prescott (1980, 1997) suggest $\\lambda = 1600$ for quarterly data.\n",
    "$\\lambda = 1600$ is also the base of adjustment for different time series data frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.filters.hp_filter import hpfilter\n",
    "from statsmodels.tsa.api import SARIMAX\n",
    "\n",
    "file_path = 'data_example/unemp.csv'\n",
    "unemp_data = pd.read_csv(file_path)\n",
    "\n",
    "print(unemp_data.head())\n",
    "\n",
    "plt.plot(unemp)\n",
    "plt.plot(unemp_hp_trend)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Boosted HP Filter\n",
    "\n",
    "* Phillips and Shi (2019): \"[Boosting: Why You Can Use the Hodrick-Prescott Filter](http://arxiv.org/abs/1905.00175),\" arXiv: 1905.00175\n",
    "* Chen and Shi (2019): R package **[BoostedHP](https://github.com/chenyang45/BoostedHP)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cointegration\n",
    "\n",
    "In a regression\n",
    "$$y_t = \\beta x_t  + e_t$$\n",
    "\n",
    "* If $y_t$ and $x_t$ are I(1) series\n",
    "* But a linear combination $e_t = y_t - \\beta x_t $ is I(0)\n",
    "\n",
    "then we say $y_t$ and $x_t$ are cointegrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "file_path = 'data_example/denmark.csv'\n",
    "unemp_data = pd.read_csv(file_path)\n",
    "\n",
    "print(denmark.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "period: Time index from 1974:Q1 until 1987:Q3.\n",
    "* `LRM`\tLogarithm of real money, M2.\n",
    "* `LRY`\tLogarithm of real income.\n",
    "* `LPY`\tLogarithm of price deflator.\n",
    "* `IBO`\tBond rate.\n",
    "* `IDE`\tBank deposit rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sjd = denmark[[\"LRM\", \"LRY\", \"IBO\", \"IDE\"]]\n",
    "plt.plot(sjd[[\"IBO\", \"IDE\"]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y = sjd.iloc[:, 2]\n",
    "x = sjd.iloc[:, 3]\n",
    "reg = sm.OLS(y, sm.add_constant(x)).fit()\n",
    "\n",
    "plt.plot(reg.resid)\n",
    "plt.axhline(y=0, linestyle='--', color='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Source of Cointegration\n",
    "\n",
    "Common shock is the source of cointegration\n",
    "\n",
    "For example, if $y_{1t} = \\mu_1 + \\beta_1 t + e_{1t}$ and $y_{2t} = \\mu_2 + \\beta_2 t + e_{2t}$, where $e_{1t}$ and $e_{2t}$ are two white noises, then the cointegration vector must be $(1,\\theta)$ where $$\\theta = - \\beta_1 / \\beta_2.$$ The first coefficient 1 in this cointegration vector is for normalization.\n",
    "\n",
    "In this example, the common trend is a determistic one. In other examples, they can also share a stochastic trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cointegration \n",
    "\n",
    "More generally, for an $m$-vector $y_t$ is cointegrated if there exists a parameter vector $\\gamma$ (normalize the first element to be 1) such that $y_t ' \\gamma$ is I(0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* The number of linear independent cointegrated vectors is called the **cointegration rank**. \n",
    "* The cointegration rank arranges from 1 to $m-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Error Correction Model\n",
    "\n",
    "Cliver Granger (Nobel prize 2001)\n",
    "\n",
    "Consider an ARDL(1,1) model\n",
    "$$ y_t  = \\mu + \\beta_0 x_t + \\beta_1 x_{t-1} + \\gamma_1 y_{t-1} + e_t. $$\n",
    "If $\\beta_0 = \\beta_1 = 0$, no *Granger causality* between $X$ and $Y$.\n",
    "When $X$ and $Y$ are both nonstationary, standard OLS inference is invalid.\n",
    "\n",
    "Subtract $y_{t-1}$ from both sides of \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta y_t & = \\mu + \\beta_0 x_t + \\beta_1 x_{t-1} + (\\gamma_1 -1 ) y_{t-1} + e_t  \\\\\n",
    "           & = \\mu + \\beta_0 \\Delta x_t + (\\beta_1 + \\beta_0) x_{t-1} + (\\gamma_1 -1 ) y_{t-1} + e_t  \\\\\n",
    "           & = \\mu + \\beta_0 \\Delta x_t + (\\gamma_1 -1 )( y_{t-1} - \\theta x_{t-1} ) + e_t  \n",
    "\\end{align*}\n",
    "$$\n",
    "where $\\theta =  (\\beta_1 + \\beta_0)/(1 - \\gamma_1)$.\n",
    "\n",
    "* A short-run relationship $\\Delta y_t \\sim \\mu + \\beta_0 \\Delta x_t + e_t$.\n",
    "* An long-run equilibrium error $(\\gamma_1 - 1 ) (y_{t-1} - \\theta x_{t-1} ) $.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "When $y_t$ is nonstationary\n",
    "\n",
    "\n",
    "* First difference recovers stationarity\n",
    "* Useful to identify spurious regression\n",
    "* Can be estimated either by OLS or by NLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Predictive Regression\n",
    "\n",
    "In the regression \n",
    "\n",
    "$$\n",
    "y_t = \\mu_y + \\beta_1 x_{t-1} + e_{yt}\n",
    "$$\n",
    "\n",
    "* $y_t$ is stationary \n",
    "* The predictor $x_t$ is highly persistent:\n",
    "\n",
    "$$\n",
    "x_t = \\mu_x + \\gamma x_{t-1} + e_{xt}\n",
    "$$ \n",
    "\n",
    "with $\\gamma$ is close to 1.\n",
    "\n",
    "* Even if $E[e_{yt} | x_{t-1} ] = 0$, OLS estimator of $\\beta_1$ is biased in finite sample when $e_{yt}$ and $e_{xt}$ are correlated (Stambaugh, 1999)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Lee, Shi and Gao (2018): \"[On LASSO for Predictive Regression](https://arxiv.org/abs/1810.03140),\" arXiv: 1810.03140\n",
    "* Find new behavior of popular machine learning methods in predictive regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "d0 = pd.read_csv(\"data_example/PredictorData2021.csv\")\n",
    "\n",
    "# Filter the data\n",
    "d0 = d0[d0['yyyymm'] > 196000]\n",
    "\n",
    "# Select specific columns\n",
    "d0 = d0[['yyyymm', 'Index', 'D12', 'E12', 'b/m', 'CAPE', 'lty', 'tbl', 'lspread', 'svar']]\n",
    "\n",
    "# Print the first few rows of the DataFrame\n",
    "print(d0.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Vector Autoregression (VAR)\n",
    "\n",
    "Christopher Sims (Nobel Prize 2011)\n",
    "\n",
    "An $m$-equation system\n",
    "$$ y_t = \\mu + \\Gamma_1 y_{t-1} + \\cdots + \\Gamma_p y_{t-p} + v_t $$\n",
    "where $E[ v_t v_t'] = \\Omega$.\n",
    "\n",
    "For prediction purpose, as a reduced-form of structural simultaneous equations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimation\n",
    "\n",
    "* For consistency and asymptotic normality, use OLS equation by equation\n",
    "* For asymptotic efficient, use multiple-equation GLS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Invertibility\n",
    "\n",
    "Write the VAR(p) as\n",
    "$$ (I_m - \\Gamma (L) ) y_t = \\mu + v_t $$ \n",
    "where $\\Gamma(z) = \\Gamma_1 z + \\cdots + \\Gamma_p z^p$. \n",
    "\n",
    "Stable means that all roots of the $p$th order polynomial equation $$ I_m - \\Gamma(z)  = 0_m $$ lies out of the unit circle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Impulse Response Function\n",
    "\n",
    "IRF characterizes the diffusion of an exogenous shock with the dynamic system.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_t & = (I_m - \\Gamma(L) )^{-1} (\\mu + v_t) \\\\\n",
    "    & = \\bar{y} + \\left( v_t + \\sum_{i=1}^{\\infty} A_i v_{t-i} \\right)\n",
    "\\end{align*}\n",
    "$$ where $\\bar{y} = (I_m - \\Gamma(L) )^{-1} \\mu = ( I_m + \\sum_{i=1}^{\\infty} A_i ) \\mu $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select specific columns\n",
    "d1 = d0[['tbl', 'lty', 'Rfree', 'ntis']]\n",
    "\n",
    "# Plot the data\n",
    "d1.plot(subplots=True, layout=(4, 1), figsize=(10, 8), title=\"\", legend=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "* `ntis`: net equity expansion\n",
    "* `tbl`: treasury bill rates () The stationary predictors\n",
    "* `lty`: long-term yield\n",
    "* `Rfree`: risk-free rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as tsa\n",
    "\n",
    "# Fit a VAR model with lag order 2\n",
    "mod_var = tsa.VAR(d1).fit(2)\n",
    "\n",
    "# Print the model summary\n",
    "print(mod_var.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the impulse response function\n",
    "irf_var = mod_var.irf(10)  # Choose the number of periods for IRF, e.g., 10\n",
    "\n",
    "# Print the IRF results\n",
    "print(irf_var.impulse_response)\n",
    "\n",
    "# Plot the IRF\n",
    "irf_var.plot(impulse='Rfree', response=['Rfree', 'tbl'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Structural VAR\n",
    "\n",
    "* Unrestricted VAR: too many parameters? $m+p\\cdot m^2 + m(m+1)/2$\n",
    "* Use economic theory to reduce the number of unknown parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# VECM Representation\n",
    "\n",
    "Suppose there are $r$ cointegration relationship in $y_t$. For the $m$-equation VAR system \n",
    "\n",
    "$$\n",
    "y_t = \\Gamma y_{t-1} + e_t,\n",
    "$$ \n",
    "\n",
    "we can rewrite it as\n",
    "\n",
    "$$ \n",
    "\\Delta y_t = (\\Gamma - I_m) y_{t-1} + e_t = \\Pi y_{t-1} + e_t.\n",
    "$$\n",
    "\n",
    "* Since LHS is stationary, the $m\\times m$ matrix $\\Pi = \\Gamma - I_m$ on the RHS must only have rank at most $r$. \n",
    "* Otherwise, the RHS will be I(1) and the two sides of the equation are unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Johansen Test\n",
    "\n",
    "\n",
    "* VECM is the base for the cointegration rank test (Johansen, 1992).\n",
    "\n",
    "* Numerical examaple: The result shows that there is only 1 cointegration relationship among the 4 time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, coint_johansen\n",
    "\n",
    "# Assuming d1 is a pandas DataFrame\n",
    "d1.index = pd.period_range('1960-01', periods=len(d1), freq='M')\n",
    "\n",
    "# Perform the Johansen cointegration test\n",
    "result = coint_johansen(d1, det_order=0, k_ar_diff=2)\n",
    "\n",
    "# Print the results\n",
    "print(result.lr1)\n",
    "print(result.lr2)\n",
    "print(result.cvt)\n",
    "print(result.cvm)\n",
    "\n",
    "# Fit the VECM model\n",
    "vecm = VECM(d1, k_ar_diff=2, coint_rank=2, deterministic=\"co\")\n",
    "vecm_fit = vecm.fit()\n",
    "\n",
    "# Print the VECM model results\n",
    "print(vecm_fit.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.vector_ar.vecm import VECM, select_order\n",
    "from statsmodels.tsa.vector_ar.var_model import VAR\n",
    "\n",
    "# Assuming d1 is a pandas DataFrame\n",
    "lag_order = select_order(d1, maxlags=2, deterministic=\"co\", method=\"eigen\").selected_orders['aic']\n",
    "vecm = VECM(d1, k_ar_diff=lag_order, coint_rank=2, deterministic=\"co\").fit()\n",
    "\n",
    "# VECM to VAR conversion\n",
    "var_model = vecm.to_var()\n",
    "\n",
    "# Calculate impulse response functions\n",
    "irf = var_model.irf(10)  # 10 periods\n",
    "\n",
    "# Plot impulse response functions\n",
    "irf.plot(impulse=\"Rfree\", response=[\"Rfree\", \"tbl\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating VECM by OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "\n",
    "# Assuming vecm is the fitted VECM model\n",
    "alpha = vecm.alpha\n",
    "beta = vecm.beta\n",
    "\n",
    "# Print alpha and beta\n",
    "print(\"Alpha:\")\n",
    "print(alpha)\n",
    "\n",
    "print(\"\\nBeta:\")\n",
    "print(beta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Future of Time Series Study\n",
    "\n",
    "* Classical methods\n",
    "* Time series model for discrete choice model\n",
    "* Time series dimension of big data\n",
    "    * Unstructured data\n",
    "    * Panel data"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernel_info": {
   "name": "ir"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.0"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "rise": {
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "serif"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
