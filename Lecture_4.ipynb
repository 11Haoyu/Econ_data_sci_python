{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4: Simulation\n",
    "## ECON5170 Computational Methods in Economics\n",
    "#### Author: Zhentao Shi\n",
    "#### Date: July 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation\n",
    "\n",
    "Probability theory has an infamous inception for its association with gambling.\n",
    "Monte Carlo, the European casino capital, is another unfortunate presence.\n",
    "However, naming it Macau simulation or Hong Kong Jockey Club simulation does not make me feel any better.\n",
    "I decide to simply call it \"simulation\".\n",
    "\n",
    "Simulation has been widely used for (i) checking finite-sample performance of asymptotic theory; (ii) bootstrap, an automated inference procedure;\n",
    "(iii) generating non-standard distributions; (iv) approximating integrals with no analytic expressions. In this lecture, we will focus on (i) and (ii), whereas (iii) and (iv)\n",
    "will be deferred to the next lecture on integration.\n",
    "\n",
    "\n",
    "From now on, we will start to write script. A script is a piece of code for a particular\n",
    "purpose. We do not write a script of thousands of lines from the beginning\n",
    "to the end; we develop it recursively. We cut a big job into small manageable tasks.\n",
    "Write a small piece, test it, and perhaps encapsulate it into a user-defined function.\n",
    "Small pieces are integrated by the super structure. This is just like building an Airbus 380.\n",
    "The engines and wings are made in UK, the fuselage is made in Germany and so on.\n",
    "All pieces are assembled in Toulouse, France, and then the giant steel bird can fly.\n",
    "Finally, add comments to the script to facilitate\n",
    "readability. Without comments you will forget\n",
    "what you did when you open the script again one month later.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Example**\n",
    "\n",
    "Zu Chongzhi (429--500 AD), an ancient Chinese mathematician, calculated $\\pi$ being between 3.1415926 and 3.1415927, which\n",
    "for 900 years held the world record of the most accurate $\\pi$.\n",
    "He used a deterministic approximation algorithm.\n",
    "Now imagine that we present to Zu Chongzhi, with full respect and admiration, a modern PC. How can he achieve a better approximation? Of course, we suppose that he would not google it.\n",
    "\n",
    "Standing on the shoulder of laws of large numbers, $\\pi$ can be approximated by stochastic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-zaw7g19d because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "# Import the NumPy library\n",
    "import numpy as np\n",
    "# Import the Pandas library\n",
    "import pandas as pd\n",
    "# Import the SciPy library\n",
    "from scipy.sparse import csr_matrix \n",
    "# Import the Random library\n",
    "import random\n",
    "# Import System Time\n",
    "import datetime\n",
    "# Import Math\n",
    "import math\n",
    "# Import statistics\n",
    "import statistics\n",
    "# Import MathPlotLib\n",
    "import matplotlib.pyplot as plt\n",
    "# Import Daytime\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.1328]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.matrix"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 10000\n",
    "Z = np.random.rand(n, 2)\n",
    "Z = np.matrix(Z)\n",
    "\n",
    "inside = np.mean((np.sqrt((np.square(Z-0.5)).sum(axis=1)) <= 0.5), axis=0)\n",
    "pi_hat = 4 * inside\n",
    "\n",
    "print(pi_hat)\n",
    "type(pi_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite Sample Evaluation\n",
    "\n",
    "In the real world, a sample is finite. The distribution of a statistic in finite sample depends on \n",
    "the sample size $n$, which has simple a mathematical expression only in rare cases. Fortunately,\n",
    "the expression can often be simplified when we imagine the sample size being arbitrarily large.\n",
    "Asymptotic theory is such apparatus to approximate finite sample distributions.\n",
    "It is so far the best mathematical tool that helps us\n",
    "understand the behavior of estimators and tests, either in econometrics or in statistics in general.\n",
    "Simulation is one way to evaluate the accuracy of approximation.\n",
    "\n",
    "Even though real data empirical example can also be used to illustrate a statistical procedure,\n",
    "artificial data are convenient and boast advantages. The prevalent paradigm in statistics is\n",
    "to assume that the data are generated from a model. We, as researchers, check how close the estimate is to\n",
    "the model, which is often characterized by a set of unknown parameters. In simulation\n",
    "we have full control of the data generation process, so we also know the\n",
    "true parameter.\n",
    "In a real example, however, we have no knowledge about the true model, so we cannot directly\n",
    "evaluate the quality of parameter estimation.\n",
    "\n",
    "(It would be a different story if we are mostly interested in prediction, as we often\n",
    "encounter in machine learning. In such cases, we can split the data into two parts: one part\n",
    "for modeling and estimation, and the other for verification.)\n",
    "\n",
    "\n",
    "**Example**\n",
    "\n",
    "In OLS theory, the classical approach is to view $X$ as fixed regressions, and only\n",
    "cares about the randomness of the error term.\n",
    "Modern econometrics textbook emphasizes that a random $X$ is more appropriate\n",
    "for econometrics applications. In rigorous textbooks, the moment of $X$ is explicitly\n",
    "stated.\n",
    "Is asymptotic inferential theory for the OLS estimator---consistency and asymptotic normality---valid when $X$ follows a\n",
    "[Pareto distribution](https://en.wikipedia.org/wiki/Pareto_distribution) with shape coefficient 1.5?\n",
    "(A Pareto distribution with shape coefficient between 1 and 2 has finite mean but infinite variance.)\n",
    "\n",
    " 1. given sample size, get OLS `b_hat` and its associated `t_value`.\n",
    " 2. wrap `t_value` as a user-defined function so that we can replicate for many times.\n",
    " 3. given sample size, report the size under two distributions.\n",
    " 4. wrap it again as a user-defined function, ready for different sample sizes.\n",
    " 5. develop the super structure.\n",
    " 6. add comments and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(888)\n",
    "# set the parameters\n",
    "Rep = 10\n",
    "b0 = np.ones((2,1))\n",
    "df = 1 # t dist. with df = 1 is Cauchy\n",
    "n = 10\n",
    "# the workhorse functions\n",
    "def simulation(n, dist = \"Normal\", df = df):\n",
    "    # a function gives the t-value under the null\n",
    "    if dist == \"Normal\":\n",
    "        e = np.random.rand(n)\n",
    "        e = e.reshape(n,1)\n",
    "    elif dist == \"T\":\n",
    "        e = np.random.standard_t(df, size=n)\n",
    "        e = e.reshape(n,1)\n",
    "        \n",
    "    X = np.hstack((np.ones((n, 1)), np.random.pareto(a = 1.5, size = (n, 1))))\n",
    "    y = np.dot(X, b0) + e\n",
    "    del e\n",
    "    \n",
    "    bhat = np.dot(np.linalg.inv(np.dot( X.T, X ) ), np.dot( X.T, y ) ) \n",
    "    bhat2 = np.array(bhat[1,0]) # parameter we want to test\n",
    "    \n",
    "    e_hat = y - np.dot(X, bhat)\n",
    "    sigma_hat_square = np.sum(np.square(e_hat))/(n-2)\n",
    "    sig_B = np.dot(np.dot(X.T, X), sigma_hat_square)\n",
    "    t_value_2 = (bhat2 - b0[1]) / (math.sqrt(sig_B[1,1]))\n",
    "\n",
    "    out = np.array([(bhat2), (t_value_2)], dtype =[('bhat2', float), ('t_value', float)])\n",
    "    return(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(list(range(Rep)))\n",
    "a = list(range(Rep))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### report the empirical test size implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (1655698511.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    Res = apply(fun = simulation(i), args(n, \"normal\"))\u001b[0m\n\u001b[0m                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TEST_SIZE = np.repeat(0, [3], axis=0)\n",
    "\n",
    "np.apply_along_axis(simulation, axis = 0, arr = a )\n",
    "\n",
    "Res = apply(fun = simulation(i), args(n, \"normal\"))\n",
    "# # report the empirical test size\n",
    "# report = function(n){\n",
    "#   # collect the test size from the two distributions\n",
    "#   # this function contains some repetitive code, but is OK for such a simple one\n",
    "#   TEST_SIZE = rep(0,3)\n",
    "\n",
    "#   # e ~ normal distribution, under which the t-dist is exact\n",
    "#   Res = ldply( .data = 1:Rep, .fun = function(i) simulation(n, \"Normal\")  )\n",
    "#   TEST_SIZE[1] = mean( abs(Res$t_value) > qt(.975, n-2) )\n",
    "#   TEST_SIZE[2] = mean( abs(Res$t_value) > qnorm(.975) )\n",
    "\n",
    "#   # e ~ t-distribution, under which the exact distribution is complicated.\n",
    "#   # we rely on asymptotic normal distribution for inference instead\n",
    "#   Res = ldply( .data = 1:Rep, .fun = function(i) simulation(n, \"T\", df)  )\n",
    "#   TEST_SIZE[3] = mean( abs(Res$t_value) > qnorm(.975) )\n",
    "\n",
    "#   return(TEST_SIZE)\n",
    "# }\n",
    "\n",
    "\n",
    "# pts0 = Sys.time()\n",
    "# # run the calculation of the empirical sizes for different sample sizes\n",
    "# NN = c(5, 10, 200, 5000)\n",
    "# RES = ldply(.data = NN, .fun = report )\n",
    "# names(RES) = c(\"exact\", \"normal.asym\", \"cauchy.asym\") # to make the results readable\n",
    "# RES$n = NN\n",
    "# RES = RES[, c(4,1:3)] # beautify the results\n",
    "# print(RES)\n",
    "# print( Sys.time() - pts0 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
